{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.datasets import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data_a, train_labels_a), (test_data_a, test_labels_a) = imdb.load_data(nb_words=5000)\n",
    "(train_data_b, train_labels_b), (test_data_b, test_labels_b) = reuters.load_data(nb_words=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "max_text_length = 100\n",
    "\n",
    "# vectorized training data\n",
    "x_train_a = sequence.pad_sequences(train_data_a, maxlen=max_text_length)[:1000]\n",
    "x_train_b = sequence.pad_sequences(train_data_b, maxlen=max_text_length)[:1000]\n",
    "x_test_a = sequence.pad_sequences(test_data_a, maxlen=max_text_length)[:1000]\n",
    "x_test_b = sequence.pad_sequences(test_data_b, maxlen=max_text_length)[:1000]\n",
    "\n",
    "y_train_a = to_categorical(train_labels_a)[:1000]\n",
    "y_test_a = to_categorical(test_labels_a)[:1000]\n",
    "y_train_b = to_categorical(train_labels_b)[:1000]\n",
    "y_test_b = to_categorical(test_labels_b)[:1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_train_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.models import Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "vocabulary_size = 5000\n",
    "embedding_dim=50\n",
    "shared_lstm = LSTM(64)\n",
    "\n",
    "input1 = Input(shape=(max_text_length,), dtype='int32')\n",
    "input2 = Input(shape=(max_text_length,), dtype='int32')\n",
    "\n",
    "embedding1 = Embedding(input_dim=vocabulary_size, output_dim=embedding_dim, input_length=max_text_length)(input1)\n",
    "embedding2 = Embedding(input_dim=vocabulary_size, output_dim=embedding_dim, input_length=max_text_length)(input2)\n",
    "lstm_output_1=shared_lstm(embedding1)\n",
    "lstm_output_2=shared_lstm(embedding2)\n",
    "hidden_output_1 = Dense(100, activation='relu')(lstm_output_1)\n",
    "hidden_output_2 = Dense(100, activation='relu')(lstm_output_2)\n",
    "output1=Dense(2, activation='softmax')(hidden_output_1)\n",
    "output2=Dense(46, activation='softmax')(hidden_output_2)\n",
    "\n",
    "# def custom_loss(y_true, y_pred):\n",
    "#     loss1=softmax(y_true,y_pred)\n",
    "#     loss2=center_loss(y_true,fc)\n",
    "#     return loss1+lambda*loss2\n",
    "\n",
    "model = Model(inputs=[input1, input2], outputs=[output1, output2])\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss=['categorical_crossentropy', 'categorical_crossentropy'], metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit([x_train_a, x_train_b],[y_train_a, y_train_b], nb_epoch=10, batch_size=512, validation_data=([x_test_a, x_test_b], [y_test_a, y_test_b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_train_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
